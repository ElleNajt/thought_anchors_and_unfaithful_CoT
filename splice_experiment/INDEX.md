# Splice Experiment - Start Here

## What is This?

This is a **self-contained experiment** to test whether high-delta cue_p sentences act as "anchors" in chain-of-thought reasoning.

## The Core Idea

We've identified sentences that cause **massive jumps** in the probability of outputting the hinted answer (up to 0.8 increase!). This experiment tests:

**Do these sentences actually cause the model to lock onto the hinted answer?**

We test this by:
1. Taking a hinted reasoning chain
2. Right before a high-delta sentence, **switch to unhinted reasoning**
3. See if the final answer changes

## Quick Navigation

### ğŸ“– New to this experiment?
â†’ Start with **[README.md](README.md)** for the experiment overview

### ğŸš€ Ready to run it?
â†’ Follow **[QUICKSTART.md](QUICKSTART.md)** for step-by-step instructions

### ğŸ”¬ Want scientific details?
â†’ Read **[EXPERIMENT_OVERVIEW.md](EXPERIMENT_OVERVIEW.md)** for hypotheses and methodology

### ğŸ“‚ Need to find a specific file?
â†’ Check **[FILE_GUIDE.md](FILE_GUIDE.md)** for complete file documentation

## Three-Step Getting Started

```bash
# Step 1: Test your setup
python test_setup.py

# Step 2: Run a small example
./run_example.sh
# (or manually: python run_splice_experiment.py --cot-data PATH --delta-threshold 0.7 --problems 3,288,59)

# Step 3: Analyze results
python analyze_results.py results/TIMESTAMP/splice_results.json --cot-data PATH
```

## File Structure

```
splice_experiment/
â”œâ”€â”€ INDEX.md                    â† You are here
â”œâ”€â”€ README.md                   â† Experiment overview
â”œâ”€â”€ QUICKSTART.md               â† Step-by-step guide
â”œâ”€â”€ EXPERIMENT_OVERVIEW.md      â† Scientific details
â”œâ”€â”€ FILE_GUIDE.md               â† Complete file reference
â”‚
â”œâ”€â”€ run_splice_experiment.py    â† Main experiment script
â”œâ”€â”€ analyze_results.py          â† Analysis script
â”œâ”€â”€ test_setup.py               â† Setup verification
â”œâ”€â”€ run_example.sh              â† Quick test script
â”‚
â”œâ”€â”€ config.py                   â† Configuration
â”œâ”€â”€ requirements.txt            â† Dependencies
â””â”€â”€ .gitignore                  â† Git ignore rules
```

## What You Need

**Data Requirements:**
- âœ… Delta analysis CSV (already exists in parent project)
- âœ… MMLU questions (already exists in parent project)
- âš ï¸ **Original CoT responses** (you need to specify the path)

**Environment:**
- âœ… Python 3.7+
- âœ… OpenRouter API key (in `.env`)
- âœ… Dependencies from `requirements.txt`

## Expected Output

After running the experiment, you'll get:

```
results/
â””â”€â”€ YYYYMMDD_HHMMSS/
    â”œâ”€â”€ splice_results.json           # Raw experimental data
    â”œâ”€â”€ metadata.json                  # Configuration used
    â”œâ”€â”€ summary.json                   # Quick summary stats
    â””â”€â”€ visualizations/
        â”œâ”€â”€ statistics.csv             # Detailed statistics
        â”œâ”€â”€ delta_vs_drop_scatter.png  # Does delta predict drop?
        â”œâ”€â”€ probability_comparison_bars.png
        â”œâ”€â”€ splice_similarity.png
        â””â”€â”€ problem_*_distribution.png # Individual plots
```

## Key Insight You're Testing

**If high-delta sentences are true anchors:**
- Removing them should break the anchoring effect
- Answer distribution should shift away from hinted answer
- Shift should be proportional to the original delta size

**If they're not anchors:**
- Removing them won't matter much
- Model will still output similar distributions
- No relationship between delta size and effect

## Next Steps

1. **First time?** â†’ [QUICKSTART.md](QUICKSTART.md)
2. **Want details?** â†’ [EXPERIMENT_OVERVIEW.md](EXPERIMENT_OVERVIEW.md)
3. **Need help?** â†’ [FILE_GUIDE.md](FILE_GUIDE.md) has troubleshooting

## Questions?

This is a complete, self-contained experiment. All the infrastructure you need is here:
- âœ… Data loading and preprocessing
- âœ… API integration for sampling
- âœ… Statistical analysis
- âœ… Visualization generation
- âœ… Documentation and examples

Just point it at your CoT data and run!

